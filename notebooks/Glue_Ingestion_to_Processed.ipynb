{
	"metadata": {
		"kernelspec": {
			"display_name": "Glue PySpark",
			"language": "python",
			"name": "glue_pyspark"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "Python_Glue_Session",
			"pygments_lexer": "python3"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# AWS Glue Studio Notebook\n##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "###  Code Setup\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 4.0\n%worker_type G.1X\n%number_of_workers 2\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\nfrom pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType, FloatType, TimestampType\nfrom pyspark.sql.functions import *\n\nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"editable": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.5 \nCurrent idle_timeout is None minutes.\nidle_timeout has been set to 2880 minutes.\nSetting Glue version to: 4.0\nPrevious worker type: None\nSetting new worker type to: G.1X\nPrevious number of workers: None\nSetting new number of workers to: 2\nTrying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 2\nIdle Timeout: 2880\nSession ID: 9a2e5b7d-b0c4-4661-b978-7e739bf4af21\nApplying the following default arguments:\n--glue_kernel_version 1.0.5\n--enable-glue-datacatalog true\nWaiting for session 9a2e5b7d-b0c4-4661-b978-7e739bf4af21 to get into ready status...\nSession 9a2e5b7d-b0c4-4661-b978-7e739bf4af21 has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Customer csv -> Parquet\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "# File path of the CSV file\nfile_path = \"s3://sidd-de-on-olist-data/raw/customers.csv\"\n\n# Read the CSV file into a DynamicFrame\ncustomer_df = glueContext.create_dynamic_frame.from_options(\n    connection_type=\"s3\",\n    connection_options={\"paths\": [file_path]},\n    format=\"csv\",\n    format_options={\"withHeader\": \"true\"}  # If the CSV file has a header\n)\n\noutput_parquet_path = 's3://sidd-de-on-olist-data/processed/customers/'\nS3bucket_node3 = glueContext.write_dynamic_frame.from_options(\n    frame= customer_df,\n    connection_type=\"s3\",\n    format=\"glueparquet\",\n    connection_options={\"path\": output_parquet_path, \"partitionKeys\": []},\n    format_options={\"compression\": \"snappy\"},\n    transformation_ctx=\"S3bucket_node3\",\n    )",
			"metadata": {
				"trusted": true,
				"editable": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Olist Order Items csv -> Parquet",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "file_path = \"s3://sidd-de-on-olist-data/raw/order_items.csv\"\n\n# Read the CSV file into a DynamicFrame\norder_items_df = glueContext.create_dynamic_frame.from_options(\n    connection_type=\"s3\",\n    connection_options={\"paths\": [file_path]},\n    format=\"csv\",\n    format_options={\"withHeader\": \"true\"}  # If the CSV file has a header\n)\n\nApplyMapping_Order_Items = ApplyMapping.apply(\n    frame=order_items_df,\n    mappings=[\n        ('order_id', 'string', 'order_id', 'string'),\n        ('order_item_id', 'string', 'order_item_id', 'integer'),\n        ('product_id', 'string', 'product_id', 'string'),\n        ('seller_id', 'string', 'seller_id', 'string'),\n        ('shipping_limit_date', 'string', 'shipping_limit_date', 'timestamp'),\n        ('price', 'string', 'price', 'float'),\n        ('freight_value', 'string', 'freight_value', 'float')\n    ],\n    transformation_ctx=\"ApplyMapping_Order_Items\",\n)\n\nApplyMapping_Order_Items = ApplyMapping_Order_Items.toDF()\nApplyMapping_Order_Items = ApplyMapping_Order_Items.withColumn(\"total_price\", \\\n                        round(col(\"price\")*col(\"order_item_id\") + col(\"freight_value\")*col(\"order_item_id\"), 2))\n\noutput_parquet_path = 's3://sidd-de-on-olist-data/processed/order_items/'\n\nApplyMapping_Order_Items.write.mode(\"overwrite\").parquet(output_parquet_path)",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:127: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Order_payments csv -> Parquet",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "file_path = \"s3://sidd-de-on-olist-data/raw/order_payments.csv\"\n\n# Read the CSV file into a DynamicFrame\norder_payments_df = glueContext.create_dynamic_frame.from_options(\n    connection_type=\"s3\",\n    connection_options={\"paths\": [file_path]},\n    format=\"csv\",\n    format_options={\"withHeader\": \"true\"}  # If the CSV file has a header\n)\n\norder_payments_df.printSchema()",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n|-- order_id: string\n|-- payment_sequential: string\n|-- payment_type: string\n|-- payment_installments: string\n|-- payment_value: string\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "\nApplyMapping_Order_Payments = ApplyMapping.apply(\n    frame=order_payments_df,\n    mappings=[\n        ('order_id', 'string', 'order_id', 'string'),\n        ('payment_sequential', 'string', 'payment_sequential', 'integer'),\n        ('payment_type', 'string', 'payment_type', 'string'),\n        ('payment_installments', 'string', 'payment_installments', 'integer'),\n        ('payment_value', 'string', 'payment_value', 'float')\n    ],\n    transformation_ctx=\"ApplyMapping_Order_Payments\",\n)\n\nApplyMapping_Order_Payments = ApplyMapping_Order_Payments.toDF()\n\noutput_parquet_path = 's3://sidd-de-on-olist-data/processed/order_payments/'\n\nApplyMapping_Order_Payments.write.mode(\"overwrite\").parquet(output_parquet_path)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "file_path = \"s3://sidd-de-on-olist-data/raw/order_reviews.csv\"\n\n# Read the CSV file into a DynamicFrame\norder_reviews_df = glueContext.create_dynamic_frame.from_options(\n    connection_type=\"s3\",\n    connection_options={\"paths\": [file_path]},\n    format=\"csv\",\n    format_options={\"withHeader\": \"true\"}  # If the CSV file has a header\n)\n\norder_reviews_df.printSchema()",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "plaintext"
				}
			},
			"execution_count": 6,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n|-- review_id: string\n|-- order_id: string\n|-- review_score: string\n|-- review_comment_title: string\n|-- review_comment_message: string\n|-- review_creation_date: string\n|-- review_answer_timestamp: string\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "ApplyMapping_Order_Reviews = ApplyMapping.apply(\n    frame=order_reviews_df,\n    mappings=[\n        ('review_id', 'string', 'review_id', 'string'),\n        ('order_id', 'string', 'order_id', 'string'),\n        ('review_score', 'string', 'review_score', 'integer'),\n        ('review_comment_title', 'string', 'review_comment_title', 'string'),\n        ('review_comment_message', 'string', 'review_comment_message', 'string'),\n        ('review_creation_date', 'string', 'review_creation_date', 'timestamp'),\n        ('review_answer_timestamp', 'string', 'review_answer_timestamp', 'timestamp'),\n    ],\n    transformation_ctx=\"ApplyMapping_Order_Reviews\",\n)\n\nApplyMapping_Order_Reviews = ApplyMapping_Order_Reviews.toDF()\n\nApplyMapping_Order_Reviews = ApplyMapping_Order_Reviews.drop(col('review_comment_message'))\n\noutput_parquet_path = 's3://sidd-de-on-olist-data/processed/order_reviews/'\n\nApplyMapping_Order_Reviews.write.mode(\"overwrite\").parquet(output_parquet_path)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "file_path = \"s3://sidd-de-on-olist-data/raw/orders.csv\"\n\n# Read the CSV file into a DynamicFrame\norders_df = glueContext.create_dynamic_frame.from_options(\n    connection_type=\"s3\",\n    connection_options={\"paths\": [file_path]},\n    format=\"csv\",\n    format_options={\"withHeader\": \"true\"}  # If the CSV file has a header\n)\n\nApplyMapping_Orders = ApplyMapping.apply(\n    frame=orders_df,\n    mappings=[\n        ('order_id', 'string', 'order_id', 'string'),\n        ('customer_id', 'string', 'customer_id', 'string'),\n        ('order_status', 'string', 'order_status', 'string'),\n        ('order_purchase_timestamp', 'string', 'order_purchase_timestamp', 'timestamp'),\n        ('order_approved_timestamp', 'string', 'order_approved_timestamp', 'timestamp'),\n        ('order_delivered_carrier_date', 'string', 'order_delivered_carrier_date', 'timestamp'),\n        ('order_delivered_customer_date', 'string', 'order_delivered_customer_date', 'timestamp'),\n        ('order_estimated_delivery_date', 'string', 'order_estimated_delivery_date', 'timestamp')\n    ],\n    transformation_ctx=\"ApplyMapping_Orders\",\n)\n\nApplyMapping_Orders = ApplyMapping_Orders.toDF()\n\nApplyMapping_Orders = ApplyMapping_Orders.filter(\"order_status = 'delivered'\")\nApplyMapping_Orders = ApplyMapping_Orders.drop(col('order_delivered_carried_date'))\n\noutput_parquet_path = 's3://sidd-de-on-olist-data/processed/orders/'\n\nApplyMapping_Orders.write.mode(\"overwrite\").parquet(output_parquet_path)",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "plaintext"
				}
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "file_path = \"s3://sidd-de-on-olist-data/raw/products.csv\"\n\n# Read the CSV file into a DynamicFrame\nproducts_df = glueContext.create_dynamic_frame.from_options(\n    connection_type=\"s3\",\n    connection_options={\"paths\": [file_path]},\n    format=\"csv\",\n    format_options={\"withHeader\": \"true\"}  # If the CSV file has a header\n)\n\nproducts_df.printSchema()",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "plaintext"
				}
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n|-- product_id: string\n|-- product_category: string\n|-- product_name_length: string\n|-- product_description_length: string\n|-- product_photos_qty: string\n|-- product_weight_g: string\n|-- product_length_cm: string\n|-- product_height_cm: string\n|-- product_width_cm: string\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "\nApplyMapping_products = ApplyMapping.apply(\n    frame=products_df,\n    mappings=[\n        ('product_id', 'string', 'product_id', 'string'),\n        ('product_category', 'string', 'product_category', 'string'),\n        ('product_name_lenght', 'string', 'product_name_lenght', 'integer'),\n        ('product_description_lenght', 'string', 'product_description_lenght', 'integer'),\n        ('product_photos_qty', 'string', 'product_photos_qty', 'integer'),\n        ('product_weight_g', 'string', 'product_weight_g', 'integer'),\n        ('product_length_cm', 'string', 'product_length_cm', 'integer'),\n        ('product_height_cm', 'string', 'product_height_cm', 'integer'),\n        ('product_width_cm', 'string', 'product_width_cm', 'integer')\n    ],\n    transformation_ctx=\"ApplyMapping_products\",\n)\n\ncolumns_to_drop = ['product_photos_qty', 'product_length_cm', 'product_height_cm', 'product_width_cm']  # List of column names to drop\nApplyMapping_products = ApplyMapping_products.drop_fields(columns_to_drop)\n\nApplyMapping_products = ApplyMapping_products.toDF()\n\nproducts_name_translation_df = glueContext.create_dynamic_frame.from_options(\n    connection_type=\"s3\",\n    connection_options={\"paths\": ['s3://sidd-de-on-olist-data/raw/product_category_name_translation.csv']},\n    format=\"csv\",\n    format_options={\"withHeader\": \"true\"}  # If the CSV file has a header\n)\n\nproducts_name_translation_df = products_name_translation_df.toDF()\nproducts_transformed_df = ApplyMapping_products.join(products_name_translation_df,\\\n                                           ApplyMapping_products.product_category == products_name_translation_df.product_category_name)\n\noutput_parquet_path = 's3://sidd-de-on-olist-data/processed/products/'\n\nproducts_transformed_df.write.mode(\"overwrite\").parquet(output_parquet_path)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 8,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "file_path = \"s3://sidd-de-on-olist-data/raw/sellers.csv\"\n\n# Read the CSV file into a DynamicFrame\nsellers_df = glueContext.create_dynamic_frame.from_options(\n    connection_type=\"s3\",\n    connection_options={\"paths\": [file_path]},\n    format=\"csv\",\n    format_options={\"withHeader\": \"true\"}  # If the CSV file has a header\n)\n\nApplyMapping_sellers = ApplyMapping.apply(\n    frame=sellers_df,\n    mappings=[\n        ('seller_id', 'string', 'seller_id', 'string'),\n        ('seller_zip_code_prefix', 'string', 'seller_zip_code_prefix', 'string'),\n        ('seller_city', 'string', 'seller_city', 'string'),\n        ('seller_state', 'string', 'seller_state', 'string')\n    ],\n    transformation_ctx=\"ApplyMapping_sellers\",\n)\n\nApplyMapping_sellers = ApplyMapping_sellers.toDF()\n\noutput_parquet_path = 's3://sidd-de-on-olist-data/processed/sellers/'\n\nApplyMapping_sellers.write.mode(\"overwrite\").parquet(output_parquet_path)\n",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "plaintext"
				}
			},
			"execution_count": 21,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		}
	]
}