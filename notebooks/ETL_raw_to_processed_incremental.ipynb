{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "access_key = userdata.get('accessId')\n",
        "secret_key =userdata.get('secretId')"
      ],
      "metadata": {
        "id": "o3DvyNs7hAAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n"
      ],
      "metadata": {
        "id": "u645S5yhhuMD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7d1a401-1ab3-44ce-beb7-bb510978fcfc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com] [1 InRelease 0 B/3\u001b[0m\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com] [Connecting to ppa\u001b[0m\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.39)] [\u001b[0m\r                                                                               \rGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [872 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,375 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,125 kB]\n",
            "Fetched 4,606 kB in 2s (2,220 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "45 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=544a5f8fd08ff90865f4f71318dc46711c4f4f6983ea812d0e48b05c185c98f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "f1a0Fan0usKh",
        "outputId": "34fab8a1-423b-4852-ee16-bdd8d3d22269"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7ec58131a620>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://8c8821ed5ad4:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Our First Spark Example</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "import pyspark\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from typing import List\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "spark= SparkSession \\\n",
        "       .builder \\\n",
        "       .appName(\"Our First Spark Example\") \\\n",
        "       .getOrCreate()\n",
        "\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9S3ooNM7p-m",
        "outputId": "b1d08d69-a261-4b8f-849f-a3b890f1bba3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "date_of_load = '2024-05-01'"
      ],
      "metadata": {
        "id": "bpsoVIjrKo0X"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType, FloatType, TimestampType\n",
        "from pyspark.sql.functions import *"
      ],
      "metadata": {
        "id": "8FUrmmPo8jya"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Customer Data**"
      ],
      "metadata": {
        "id": "XEKlsN3KO6zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_schema = StructType([StructField('customer_id', StringType(), True),\\\n",
        "                              StructField('customer_unique_id', StringType(), True),\\\n",
        "                             StructField('customer_zip_code_prefix', StringType(), True),\\\n",
        "                              StructField('customer_city', StringType(), True),\n",
        "                              StructField('customer_state', StringType(),True)])"
      ],
      "metadata": {
        "id": "tSp9fKAv8yzk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.isfile(f'/content/gdrive/MyDrive/olist-incremental-load/raw-incremental/{date_of_load}/customers.csv'):\n",
        "  customer_df = spark.read.schema(customer_schema).option('header', 'true').csv(f'/content/gdrive/MyDrive/olist-incremental-load/raw-incremental/{date_of_load}/customers.csv')\n",
        "  if os.path.isdir(f'/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/customers'):\n",
        "    existing_customer_df = spark.read.parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/customers')\n",
        "    customer_df = customer_df.join(existing_customer_df, existing_customer_df.customer_id == customer_df.customer_id, 'left_anti')\n",
        "    print(customer_df.count())\n",
        "    customer_df.show()\n",
        "    customer_df.repartition(1).write.option(\"compression\", \"snappy\")\\\n",
        "    .mode('append').parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/customers')\n",
        "  else:\n",
        "    print(customer_df.count())\n",
        "    customer_df.show()\n",
        "    customer_df.repartition(1).write.option(\"compression\", \"snappy\").mode('overwrite').parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/customers')\n",
        "else:\n",
        "  print('No file found')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU5uSlSDKaeM",
        "outputId": "1ae30621-eb7a-4837-ddec-7fc316965dfa"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59\n",
            "+--------------------+--------------------+------------------------+-------------------+--------------+\n",
            "|         customer_id|  customer_unique_id|customer_zip_code_prefix|      customer_city|customer_state|\n",
            "+--------------------+--------------------+------------------------+-------------------+--------------+\n",
            "|c8881515a45dd6f97...|6c56bc412d285dc42...|                   22783|     rio de janeiro|            RJ|\n",
            "|7930549f156eea2b0...|dfe634d4b8e067879...|                   91260|       porto alegre|            RS|\n",
            "|376b286a6479ddacb...|8bc3746e85755be3c...|                   17202|                jau|            SP|\n",
            "|6f58e369991106fe6...|def127928e892d48d...|                   53610|           igarassu|            PE|\n",
            "|a35878bee339b4524...|9726a24d281565192...|                   13052|           campinas|            SP|\n",
            "|033fab69968b0d690...|fc0bcca3d8d90a812...|                   29278|              arace|            ES|\n",
            "|397e69077924b1f68...|1d3d94e6941c2196d...|                   22610|     rio de janeiro|            RJ|\n",
            "|04f6954a5161ce3f1...|73ab88904d8a60546...|                   87020|            maringa|            PR|\n",
            "|67a2903f301a08404...|8b3b343b297bb6838...|                   22775|     rio de janeiro|            RJ|\n",
            "|e0fb20baf67827e39...|d7db00ddc199284ce...|                   60744|          fortaleza|            CE|\n",
            "|96456ec75560f2ec1...|f0347c282b3654c9a...|                   12220|sao jose dos campos|            SP|\n",
            "|973bc0291bb6c58f5...|0aacde7f3bda1ae91...|                   95765|      bom principio|            RS|\n",
            "|0af8a25fb0b6f8337...|e2538fcd738167049...|                   21051|     rio de janeiro|            RJ|\n",
            "|d88ce61774a12cc15...|81de0b5d3753b115f...|                    5713|          sao paulo|            SP|\n",
            "|15eb80a894d70b008...|f7f8503e3befafa49...|                   11030|             santos|            SP|\n",
            "|a96a2a926becea8de...|c0c58988406361831...|                   22723|     rio de janeiro|            RJ|\n",
            "|93c015faf4f5b94d5...|29d404644ba0bd6a5...|                    5021|          sao paulo|            SP|\n",
            "|8d4632ec0b24f42cf...|abae4f6067389b730...|                   73900|              posse|            GO|\n",
            "|1d7851c5569233818...|f942774febec601b8...|                   25220|    duque de caxias|            RJ|\n",
            "|bfc24858928300e9b...|f5130e7cd0dc6a46c...|                   34800|              caete|            MG|\n",
            "+--------------------+--------------------+------------------------+-------------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "existing_customer_df = spark.read.parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/customers')\n",
        "existing_customer_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "451tMPKOOP4H",
        "outputId": "e3b6c955-1718-4c2f-e0b2-7e0aec3020a8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99441"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer_df = spark.read.schema(customer_schema).option('header', 'true').csv('/content/gdrive/MyDrive/raw/customers.csv')"
      ],
      "metadata": {
        "id": "lMZZVhW28ECl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Order_Items**"
      ],
      "metadata": {
        "id": "Dy3MN_rHPCWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "order_items_schema = StructType([\n",
        "    StructField('order_id', StringType(), True),\n",
        "    StructField('order_item_id', IntegerType(), True),\n",
        "    StructField('product_id', StringType(), True),\n",
        "    StructField('seller_id', StringType(), True),\n",
        "    StructField('shipping_limit_date', TimestampType(), True),\n",
        "    StructField('price', FloatType(), True),\n",
        "    StructField('freight_value', FloatType(), True)\n",
        "])\n"
      ],
      "metadata": {
        "id": "mRx2b3Nr_WNP"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.isfile(f'/content/gdrive/MyDrive/olist-incremental-load/raw-incremental/{date_of_load}/order_items.csv'):\n",
        "  order_items_df = spark.read.schema(order_items_schema).option('header', 'true')\\\n",
        "  .csv(f'/content/gdrive/MyDrive/olist-incremental-load/raw-incremental/{date_of_load}/order_items.csv')\n",
        "\n",
        "  if os.path.isdir(f'/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/order_items'):\n",
        "    existing_order_items_df = spark.read.parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/order_items')\n",
        "    # Perform left anti join to find rows in new_data that are not in existing_data\n",
        "    incremental_data = order_items_df.join(existing_order_items_df,\n",
        "                            on=['order_id', 'order_item_id', 'product_id', 'seller_id', 'shipping_limit_date', 'price',\n",
        "                                'freight_value'], how='left_anti')\\\n",
        "                                .withColumn('total_price', col('price')*col('order_item_id') + col('freight_value')*col('order_item_id'))\n",
        "    print(incremental_data.count())\n",
        "    incremental_data.show()\n",
        "    incremental_data.repartition(1).write.option(\"compression\", \"snappy\").mode('append').parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/order_items')\n",
        "\n",
        "  else:\n",
        "    order_items_df = order_items_df.withColumn('total_price', col('price')*col('order_item_id') + col('freight_value')*col('order_item_id'))\n",
        "    print(order_items_df.count())\n",
        "    order_items_df.show()\n",
        "    order_items_df.repartition(1).write.option(\"compression\", \"snappy\").mode('overwrite').parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/order_items')\n",
        "else:\n",
        "  print('No file found')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcqIwDD0PMUG",
        "outputId": "1c5951a5-2f7a-4fbb-ab1f-0fe721fa098a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62\n",
            "+--------------------+-------------+--------------------+--------------------+-------------------+------+-------------+-----------+\n",
            "|            order_id|order_item_id|          product_id|           seller_id|shipping_limit_date| price|freight_value|total_price|\n",
            "+--------------------+-------------+--------------------+--------------------+-------------------+------+-------------+-----------+\n",
            "|0096668e5b0b8e965...|            1|55782cb82e0efe052...|c003204e1ab016dfa...|2018-07-13 13:46:36| 166.9|        13.47|     180.37|\n",
            "|0a92bad75c24fdf33...|            1|2c8e38b2b220b65a3...|c8467937e403e76a8...|2018-08-17 20:25:16|  42.9|        13.64|      56.54|\n",
            "|0c38c51b8a775bccb...|            1|c3d0861113018ae43...|903037660cf848a71...|2018-08-03 18:05:11| 69.99|        23.21|       93.2|\n",
            "|103de323ece563a10...|            1|a62e25e09e05e6faf...|634964b17796e6430...|2018-08-24 03:30:00| 105.0|         9.67|     114.67|\n",
            "|1b3190b2dfa9d789e...|            1|ee406bf28024d9777...|7a67c85e85bb2ce85...|2018-03-01 15:16:14|144.99|        17.26|     162.25|\n",
            "|1e7d25f611e794f96...|            1|689c51a11e9c5daef...|b561927807645834b...|2018-08-07 20:30:23|  24.0|        19.08|      43.08|\n",
            "|1f0e3e7a13d984433...|            1|d4548e7ab697993ec...|4869f7a5dfa277a7d...|2018-08-21 04:35:11| 153.9|        13.74|     167.64|\n",
            "|234c056c50619f48d...|            1|0bbb557651f08b3c7...|cac4c8e7b1ca6252d...|2018-08-23 03:15:15| 59.99|        15.72|      75.71|\n",
            "|238652e39c5fdf89a...|            1|6a31191d5ac5852b0...|7357b52d27cbaa90f...|2018-08-02 02:05:11|118.13|        20.02|     138.15|\n",
            "|2591f6277be80b0c2...|            1|f303e2cdf0967ef1a...|1900267e848ceeba8...|2018-08-07 17:10:08| 56.99|         23.2|      80.19|\n",
            "|267519bdbe13b2f23...|            1|6392b413939939ce3...|b43d8b707f887a30f...|2018-07-09 17:31:32| 349.0|        53.16|     402.16|\n",
            "|2dd5f6a66c1d82ee0...|            1|af0a99476d96dcc1a...|04308b1ee57b6625f...|2018-08-17 04:35:17| 527.9|         21.8|      549.7|\n",
            "|34688497162fbb53b...|            1|94938d42be4ea1064...|02f623a8eb246f3c5...|2018-08-16 21:44:02| 139.0|        14.55|     153.55|\n",
            "|3794be706c3088573...|            1|8e05d659efa36ce4b...|213b25e6f54661939...|2018-08-17 17:44:33|119.85|        20.03|     139.88|\n",
            "|3aa0358c1a9b8019b...|            1|b0c8da302d49498d2...|88460e8ebdecbfecb...|2018-08-07 16:07:01|  50.2|        22.28|      72.48|\n",
            "|3decc053f76f6898a...|            1|af0a99476d96dcc1a...|04308b1ee57b6625f...|2018-08-17 14:15:16| 527.9|         21.8|      549.7|\n",
            "|4505acb3759da6b9c...|            1|0eb8e03d4ef83152c...|cac4c8e7b1ca6252d...|2018-08-13 14:44:46| 29.99|        12.51|       42.5|\n",
            "|450cb96c63e1e5b49...|            1|08d207a2357381d92...|93dc87703c046b603...|2018-06-06 06:57:03| 179.0|        22.96|  201.95999|\n",
            "|4530ebf341c28451b...|            1|4f288e27579d68e61...|7d13fca1522535862...|2018-06-28 18:21:15| 180.0|        23.19|     203.19|\n",
            "|478116017852df9d1...|            1|72f7a39ebe43db153...|1d1bbb8ac15818249...|2018-08-28 14:24:25|  51.5|         9.15|      60.65|\n",
            "+--------------------+-------------+--------------------+--------------------+-------------------+------+-------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "existing_order_item_df = spark.read.parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/order_items')\n",
        "existing_order_item_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1L29j4Q0S4fn",
        "outputId": "e28e3660-3bd3-48f9-951b-b6d7776766ac"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "112650"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Order_payments**"
      ],
      "metadata": {
        "id": "DF-Y4QfqUKWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "order_payments_schema = StructType([\n",
        "    StructField('order_id', StringType(), True),\n",
        "    StructField('payment_sequential', IntegerType(), True),\n",
        "    StructField('payment_type', StringType(), True),\n",
        "    StructField('payment_installments', IntegerType(), True),\n",
        "    StructField('payment_value', FloatType(), True)\n",
        "])\n"
      ],
      "metadata": {
        "id": "plmSdTNLAX5n"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "date_of_load = '2024-05-01'"
      ],
      "metadata": {
        "id": "CCFz8x6tZ9Zs"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.isfile(f'/content/gdrive/MyDrive/olist-incremental-load/raw-incremental/{date_of_load}/order_payments.csv'):\n",
        "  order_payments_df = spark.read.schema(order_payments_schema).option('header', 'true')\\\n",
        "  .csv(f'/content/gdrive/MyDrive/olist-incremental-load/raw-incremental/{date_of_load}/order_payments.csv')\n",
        "\n",
        "  if os.path.isdir(f'/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/order_payments'):\n",
        "    existing_order_payments_df = spark.read.parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/order_payments')\n",
        "    # Perform left anti join to find rows in new_data that are not in existing_data\n",
        "    incremental_data = order_payments_df.join(existing_order_payments_df,\n",
        "                            on=['order_id', 'payment_sequential','payment_type', 'payment_installments','payment_value'], how='left_anti')\n",
        "\n",
        "    print(incremental_data.count())\n",
        "    incremental_data.show()\n",
        "    incremental_data.repartition(1).write.option(\"compression\", \"snappy\").mode('append').parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/order_payments')\n",
        "\n",
        "  else:\n",
        "    print(order_payments_df.count())\n",
        "    order_payments_df.show()\n",
        "    order_payments_df.repartition(1).write.option(\"compression\", \"snappy\").mode('overwrite').parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/order_payments')\n",
        "else:\n",
        "  print('No file found')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE-MzEEeW0GF",
        "outputId": "ca68dff1-c11e-47a9-e103-f4a56e7d64bc"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59\n",
            "+--------------------+------------------+------------+--------------------+-------------+\n",
            "|            order_id|payment_sequential|payment_type|payment_installments|payment_value|\n",
            "+--------------------+------------------+------------+--------------------+-------------+\n",
            "|3794be706c3088573...|                 1| credit_card|                   3|       139.88|\n",
            "|34688497162fbb53b...|                 1| credit_card|                   3|       153.55|\n",
            "|6d0940a8f5fba4756...|                 1| credit_card|                  10|      2455.12|\n",
            "|920c5e9d5a8a142e7...|                 1|      boleto|                   1|        72.54|\n",
            "|63d6a91d52c3051f9...|                 1| credit_card|                   1|       177.49|\n",
            "|587e32dd528769d66...|                 1|      boleto|                   1|       189.18|\n",
            "|2dd5f6a66c1d82ee0...|                 1|      boleto|                   1|        549.7|\n",
            "|478116017852df9d1...|                 1| credit_card|                   1|        60.65|\n",
            "|450cb96c63e1e5b49...|                 1| credit_card|                   5|       201.96|\n",
            "|2591f6277be80b0c2...|                 1| credit_card|                   1|        80.19|\n",
            "|a024d7476a847e045...|                 1|      boleto|                   1|       200.33|\n",
            "|734e66350ff1d845a...|                 1| credit_card|                   1|       235.06|\n",
            "|3aa0358c1a9b8019b...|                 1| credit_card|                   1|        72.48|\n",
            "|6325af88a0611fc35...|                 1|      boleto|                   1|       100.38|\n",
            "|4505acb3759da6b9c...|                 1|      boleto|                   1|         42.5|\n",
            "|4f7dbee2068ee4100...|                 1| credit_card|                   1|        65.35|\n",
            "|d5244670e213108e7...|                 1| credit_card|                  10|       122.43|\n",
            "|ae213a9f84c777fb7...|                 1| credit_card|                   8|       398.69|\n",
            "|0c38c51b8a775bccb...|                 1| credit_card|                   1|         93.2|\n",
            "|7e708aed151d6a860...|                 1| credit_card|                   2|        44.63|\n",
            "+--------------------+------------------+------------+--------------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "existing_order_payment_df = spark.read.parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/order_payments')\n",
        "existing_order_payment_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXJp6k4kaHZS",
        "outputId": "c1c3d9c6-b1cb-4d78-cf77-2743ec2aa5c5"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "103886"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Order Reviews**"
      ],
      "metadata": {
        "id": "GSml59lmac_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "order_reviews_schema = StructType([\n",
        "    StructField('review_id', StringType(), True),\n",
        "    StructField('order_id', StringType(), True),\n",
        "    StructField('review_score', IntegerType(), True),\n",
        "    StructField('review_comment_title', StringType(), True),\n",
        "    StructField('review_comment_message', StringType(),True),\n",
        "    StructField('review_creation_date', TimestampType(), True),\n",
        "    StructField('review_answer_timestamp', TimestampType(), True)\n",
        "])\n"
      ],
      "metadata": {
        "id": "6HSxSV5DBnCU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "date_of_load = '2024-05-01'"
      ],
      "metadata": {
        "id": "Cft7RvbXbP2Y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.isfile(f'/content/gdrive/MyDrive/olist-incremental-load/raw-incremental/{date_of_load}/order_reviews.csv'):\n",
        "  order_reviews_df = spark.read.schema(order_reviews_schema).option('header', 'true')\\\n",
        "  .csv(f'/content/gdrive/MyDrive/olist-incremental-load/raw-incremental/{date_of_load}/order_reviews.csv')\n",
        "\n",
        "  if os.path.isdir(f'/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/order_reviews'):\n",
        "    existing_order_reviews_df = spark.read.parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/order_reviews')\n",
        "    # Perform left anti join to find rows in new_data that are not in existing_data\n",
        "    order_reviews = order_reviews_df.join(existing_order_reviews_df,\n",
        "                            on=['review_id', 'order_id', 'review_score', 'review_comment_title', 'review_creation_date', 'review_answer_timestamp'],\n",
        "                            how='left_anti')\n",
        "\n",
        "    print(order_reviews.count())\n",
        "    order_reviews.show()\n",
        "    order_reviews.repartition(1).write.option(\"compression\", \"snappy\").mode('append').parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/order_reviews')\n",
        "\n",
        "  else:\n",
        "\n",
        "    print(order_reviews_df.count())\n",
        "    order_reviews_df.show()\n",
        "    order_reviews_df.repartition(1).write.option(\"compression\", \"snappy\").mode('overwrite').parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/order_reviews')\n",
        "else:\n",
        "  print('No file found')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eiz_UP9aqhq",
        "outputId": "0d85884f-6e05-490c-fc63-1116c86b6666"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "708\n",
            "+--------------------+--------------------+------------+--------------------+--------------------+-----------------------+----------------------+\n",
            "|           review_id|            order_id|review_score|review_comment_title|review_creation_date|review_answer_timestamp|review_comment_message|\n",
            "+--------------------+--------------------+------------+--------------------+--------------------+-----------------------+----------------------+\n",
            "|b396ba75350276a6c...|43050a51a257b17d5...|           1|      Lamenetável...|                NULL|                   NULL|             Boa Noite|\n",
            "|        é lamentável| esta loja que ta...|        NULL| 2018-08-23 00:00:00|                NULL|                   NULL|   2018-08-30 03:02:39|\n",
            "|5d6f9cddc8335878d...|38fc895ea0a2aa253...|           5|      mega recomendo|                NULL|                   NULL|  Recebi meu produt...|\n",
            "|   SUPER RECOMENDO.\"| 2018-08-10 00:00:00|        NULL|                NULL|                NULL|                   NULL|                  NULL|\n",
            "|ae83a790a3f01e1c4...|1b3190b2dfa9d789e...|           2|                NULL| 2018-03-17 00:00:00|    2018-03-17 05:08:11|                  NULL|\n",
            "|ca4337c4d52184f5c...|71bd2b49a4e92c385...|           5|           Lindo !!!|                NULL|                   NULL|  Parabéns a loja l...|\n",
            "|A cor marrom é co...| 2018-08-23 00:00:00|        NULL|                NULL|                NULL|                   NULL|                  NULL|\n",
            "|b46e9ea6cd78b7b16...|d0fcb0e64631dcf3a...|           4|           recomendo|                NULL|                   NULL|      chegou, obrigada|\n",
            "|         mas a caixa|         a embalagem|        NULL|                NULL|                NULL|                   NULL|                  NULL|\n",
            "|amassada e é um p...| 2018-08-15 00:00:00|        NULL|                NULL|                NULL|                   NULL|                  NULL|\n",
            "|848d5324b9cb5aa4c...|d888f4591d9dd2728...|           5|    super recomendo.|                NULL|                   NULL|  Otimo deu tudo ce...|\n",
            "|           nota 10.\"| 2018-08-17 00:00:00|        NULL|                NULL|                NULL|                   NULL|                  NULL|\n",
            "|46bbfd645772dfa7b...|30524d6f42cc124d1...|           1| Produto com defeito|                NULL|                   NULL|                     \"|\n",
            "|Comprei um produt...| 2018-08-17 00:00:00|        NULL|                NULL|                NULL|                   NULL|                  NULL|\n",
            "|b4b5ada90c525bf54...|a024d7476a847e045...|           3|           Recomendo| 2018-08-23 00:00:00|    2018-08-27 11:16:28|               Tudo ok|\n",
            "|f2395ab617ccf04f0...|8624511aa767a83ed...|           1|Informação\\preocu...|                NULL|                   NULL|  Minha avaliação t...|\n",
            "|      Atenciosamente|                    |        NULL|                NULL|                NULL|                   NULL|                  NULL|\n",
            "|            Juliana\"| 2018-08-31 00:00:00|        NULL|                NULL|                NULL|                   NULL|                  NULL|\n",
            "|43fd5a322f0f3cfbe...|238652e39c5fdf89a...|           4|                NULL| 2018-08-16 00:00:00|    2018-08-17 13:44:16|                  NULL|\n",
            "|1c7b9ad19f9b7734a...|eb23b9ffbd39df83f...|           3|composição diferente|                NULL|                   NULL|  Na descrição do p...|\n",
            "+--------------------+--------------------+------------+--------------------+--------------------+-----------------------+----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "existing_order_review_df = spark.read.parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/order_reviews')\n",
        "existing_order_review_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfNUQUy7blUx",
        "outputId": "4b7d8dc9-6bcc-49f5-9945-f7274ceecd50"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104804"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Orders**"
      ],
      "metadata": {
        "id": "t9Uuj9UDeKy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_schema = StructType([\n",
        "    StructField('order_id', StringType(), True),\n",
        "    StructField('customer_id',StringType(), True),\n",
        "    StructField('order_status', StringType(), True),\n",
        "    StructField('order_purchase_timestamp', TimestampType(), True),\n",
        "    StructField('order_approved_timestamp', TimestampType(), True),\n",
        "    StructField('order_delivered_carrier_date', TimestampType(), True),\n",
        "    StructField('order_delivered_customer_date', TimestampType(), True),\n",
        "    StructField('order_estimated_delivery_date', TimestampType(), True)\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "byvnhwhvD1d4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "date_of_load = '2024-05-01'"
      ],
      "metadata": {
        "id": "Y1ACfGPyeRRk"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.isfile(f'/content/gdrive/MyDrive/olist-incremental-load/raw-incremental/{date_of_load}/orders.csv'):\n",
        "  orders_df = spark.read.schema(orders_schema).option('header', 'true')\\\n",
        "  .csv(f'/content/gdrive/MyDrive/olist-incremental-load/raw-incremental/{date_of_load}/orders.csv').drop(col('oder_delivered_carrier_date'))\n",
        "\n",
        "  if os.path.isdir(f'/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/orders'):\n",
        "    existing_orders_df = spark.read.parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/orders')\n",
        "    # Perform left anti join to find rows in new_data that are not in existing_data\n",
        "    orders = orders_df.join(existing_orders_df,\n",
        "                            on=['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp', 'order_approved_timestamp','order_delivered_customer_date',\n",
        "                                'order_estimated_delivery_date'],\n",
        "                            how='left_anti').filter(\"order_status = 'delivered' \")\n",
        "\n",
        "    print(orders.count())\n",
        "    orders.show()\n",
        "    orders.repartition(1).write.option(\"compression\", \"snappy\").mode('append').parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/orders')\n",
        "\n",
        "  else:\n",
        "\n",
        "    print(orders_df.count())\n",
        "    orders_df.show()\n",
        "    orders_df.repartition(1).write.option(\"compression\", \"snappy\").mode('overwrite').parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/orders')\n",
        "else:\n",
        "  print('No file found')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twW7wNpaeUAy",
        "outputId": "d1b553e1-14a6-41bd-8c85-63b4d26c562e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59\n",
            "+--------------------+--------------------+------------+------------------------+------------------------+-----------------------------+-----------------------------+----------------------------+\n",
            "|            order_id|         customer_id|order_status|order_purchase_timestamp|order_approved_timestamp|order_delivered_customer_date|order_estimated_delivery_date|order_delivered_carrier_date|\n",
            "+--------------------+--------------------+------------+------------------------+------------------------+-----------------------------+-----------------------------+----------------------------+\n",
            "|0c38c51b8a775bccb...|1b8d4b28ab6042710...|   delivered|     2018-07-29 17:56:09|     2018-07-29 18:05:11|          2018-09-01 00:34:24|          2018-08-20 00:00:00|         2018-08-03 12:37:00|\n",
            "|d5244670e213108e7...|b960433ecd19b8c85...|   delivered|     2018-08-11 20:55:28|     2018-08-11 21:05:14|          2018-09-01 00:36:42|          2018-08-28 00:00:00|         2018-08-13 12:14:00|\n",
            "|267519bdbe13b2f23...|8d4632ec0b24f42cf...|   delivered|     2018-07-03 16:37:35|     2018-07-05 16:13:39|          2018-09-01 00:51:37|          2018-07-31 00:00:00|         2018-07-04 06:54:00|\n",
            "|bb4eb3e71b30365a5...|e15fc5eebbb466810...|   delivered|     2018-07-24 08:10:01|     2018-07-24 11:23:32|          2018-09-01 01:22:46|          2018-08-22 00:00:00|         2018-07-25 14:06:00|\n",
            "|92de9d50e681619c1...|0e9ed7dc549f24ff1...|   delivered|     2018-08-13 17:28:36|     2018-08-13 17:44:12|          2018-09-01 02:18:43|          2018-08-22 00:00:00|         2018-08-15 13:42:00|\n",
            "|234c056c50619f48d...|44e460a655f7154cc...|   delivered|     2018-08-14 14:49:15|     2018-08-15 03:15:15|          2018-09-01 18:14:42|          2018-08-23 00:00:00|         2018-08-31 15:25:00|\n",
            "|587e32dd528769d66...|0af8a25fb0b6f8337...|   delivered|     2018-08-10 11:46:09|     2018-08-11 02:50:25|          2018-09-03 09:32:31|          2018-08-28 00:00:00|         2018-08-14 10:09:00|\n",
            "|2591f6277be80b0c2...|614e4a9149f6119fc...|   delivered|     2018-08-04 16:55:24|     2018-08-04 17:10:08|          2018-09-03 15:24:34|          2018-08-14 00:00:00|         2018-08-08 12:22:00|\n",
            "|f92d5a62c7841e7f1...|04f6954a5161ce3f1...|   delivered|     2018-08-06 18:25:54|     2018-08-09 15:50:14|          2018-09-03 15:28:36|          2018-08-24 00:00:00|         2018-08-10 14:30:00|\n",
            "|cb8372ec4562008e6...|5f1f934f0527b0822...|   delivered|     2018-08-15 14:02:53|     2018-08-17 03:09:55|          2018-09-03 15:36:49|          2018-08-22 00:00:00|         2018-08-31 14:53:00|\n",
            "|52550cee1dda83b2c...|93c015faf4f5b94d5...|   delivered|     2018-08-06 12:35:39|     2018-08-06 12:45:20|          2018-09-03 16:59:03|          2018-08-29 00:00:00|         2018-08-28 12:58:00|\n",
            "|478116017852df9d1...|ecd37231a9052d49d...|   delivered|     2018-08-24 13:59:41|     2018-08-24 14:24:25|          2018-09-03 17:18:42|          2018-08-29 00:00:00|         2018-08-30 14:58:00|\n",
            "|8624511aa767a83ed...|376b286a6479ddacb...|   delivered|     2018-08-06 15:26:36|     2018-08-06 15:44:40|          2018-09-03 17:26:49|          2018-08-29 00:00:00|         2018-08-28 12:58:00|\n",
            "|3decc053f76f6898a...|4f3ada4edfb7f58e8...|   delivered|     2018-08-05 14:02:28|     2018-08-05 14:15:16|          2018-09-03 17:31:55|          2018-08-28 00:00:00|         2018-08-28 12:58:00|\n",
            "|2dd5f6a66c1d82ee0...|d88ce61774a12cc15...|   delivered|     2018-08-02 12:07:36|     2018-08-03 04:35:17|          2018-09-03 17:38:39|          2018-08-27 00:00:00|         2018-08-28 12:58:00|\n",
            "|e175b8edb692594c9...|96456ec75560f2ec1...|   delivered|     2018-08-24 18:26:00|     2018-08-24 18:43:57|          2018-09-03 18:18:49|          2018-08-29 00:00:00|         2018-08-28 11:32:00|\n",
            "|920c5e9d5a8a142e7...|549c4324287323de0...|   delivered|     2018-08-04 23:39:27|     2018-08-07 04:15:21|          2018-09-03 18:59:30|          2018-08-16 00:00:00|         2018-08-13 15:05:00|\n",
            "|103de323ece563a10...|1d7851c5569233818...|   delivered|     2018-08-15 21:41:45|     2018-08-17 03:30:00|          2018-09-03 19:06:55|          2018-08-23 00:00:00|         2018-08-23 14:43:00|\n",
            "|3aa0358c1a9b8019b...|079d3acdd9329ed0f...|   delivered|     2018-07-30 15:27:39|     2018-07-30 16:07:01|          2018-09-03 20:31:06|          2018-08-27 00:00:00|         2018-08-14 12:56:00|\n",
            "|734e66350ff1d845a...|973bc0291bb6c58f5...|   delivered|     2018-08-03 17:05:23|     2018-08-03 17:15:27|          2018-09-03 22:50:57|          2018-08-17 00:00:00|         2018-08-28 12:08:00|\n",
            "+--------------------+--------------------+------------+------------------------+------------------------+-----------------------------+-----------------------------+----------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "existing_order_df = spark.read.parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/orders')\n",
        "existing_order_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGv4OCeBgDxn",
        "outputId": "350a0203-3d7b-4e08-cde3-27c15c3e6325"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99441"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Products data**"
      ],
      "metadata": {
        "id": "v7Vez6MjgRO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "products_schema = StructType([\n",
        "    StructField('product_id', StringType(), True),\n",
        "    StructField('product_category', StringType(), True),\n",
        "    StructField('product_name_lenght', IntegerType(), True),\n",
        "    StructField('product_description_lenght', IntegerType(), True),\n",
        "    StructField('product_photos_qty', IntegerType(), True),\n",
        "    StructField('product_weight_g', IntegerType(), True),\n",
        "    StructField('product_length_cm', IntegerType(), True),\n",
        "    StructField('product_height_cm', IntegerType(), True),\n",
        "    StructField('product_width_cm', IntegerType(), True)\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "q6ahCjaPFJci"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "date_of_load = '2024-04-01'"
      ],
      "metadata": {
        "id": "UrEyUknQgZ-Z"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.isfile(f'/content/gdrive/MyDrive/olist-incremental-load/raw-incremental/{date_of_load}/products.csv'):\n",
        "\n",
        "  products_df = spark.read.schema(products_schema).option('header', 'true')\\\n",
        "  .csv(f'/content/gdrive/MyDrive/olist-incremental-load/raw-incremental/{date_of_load}/products.csv')\n",
        "\n",
        "  products_df = products_df.drop(col('product_photos_qty'), col('product_length_cm'), col('product_height_cm'), col('product_width_cm'))\n",
        "\n",
        "  products_name_translation_df = spark.read.option('inferSchema', 'true').option('header', 'true')\\\n",
        "      .csv(f'/content/gdrive/MyDrive/olist-incremental-load/raw-incremental/{date_of_load}/product_category_name_translation.csv')\n",
        "\n",
        "  products_transformed_df = products_df.join(broadcast(products_name_translation_df),\\\n",
        "                                            products_df.product_category == products_name_translation_df.product_category_name)\\\n",
        "                                            .drop(col('product_category_name'))\\\n",
        "                                            .drop(col('product_category')).drop(col('product_name_lenght'))\\\n",
        "                                            .drop(col('product_description_lenght'))\n",
        "  products_transformed_df.count()\n",
        "\n",
        "  products_transformed_df.repartition(1).write.mode('overwrite')\\\n",
        "      .parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/products')\n",
        "else:\n",
        "  print('No file found')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge9uMmc6gW88",
        "outputId": "130dbe01-c9c9-4f81-f6fa-c49c0cf2ea4b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No file found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "existing_product_df = spark.read.parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/products')\n",
        "existing_product_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq2RnsPnhfrr",
        "outputId": "3092dcf6-ebb2-4c66-8d36-ee06259c5223"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32328"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Sellers Data**"
      ],
      "metadata": {
        "id": "hKIejafliEEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sellers_schema = StructType([StructField('seller_id', StringType(), True),\n",
        "                            StructField('seller_zip_code_prefix', StringType(), True),\n",
        "                            StructField('seller_city', StringType(), True),\n",
        "                            StructField('seller_state', StringType(), True)])\n",
        "\n"
      ],
      "metadata": {
        "id": "9wqeYUpTFxLo"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "date_of_load = '2024-04-01'"
      ],
      "metadata": {
        "id": "cAA5xnVbiKWV"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.isfile(f'/content/gdrive/MyDrive/olist-incremental-load/raw-incremental/{date_of_load}/sellers.csv'):\n",
        "\n",
        "  sellers_df = spark.read.schema(sellers_schema).option('header', 'true')\\\n",
        "  .csv(f'/content/gdrive/MyDrive/olist-incremental-load/raw-incremental/{date_of_load}/sellers.csv')\n",
        "\n",
        "  sellers_df.count()\n",
        "\n",
        "  sellers_df.repartition(1).write.mode('overwrite')\\\n",
        "      .parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/sellers')\n",
        "else:\n",
        "  print('No file found')"
      ],
      "metadata": {
        "id": "ntLzzTcmIj5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87df5ef9-dc19-415e-a70f-e8bf4ed6b901"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No file found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "existing_seller_df = spark.read.parquet('/content/gdrive/MyDrive/olist-incremental-load/processed-incremental/sellers')\n",
        "existing_seller_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iuq7ErCic1w",
        "outputId": "7f587a35-6364-42ab-fd7a-885669a8fda1"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3095"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    }
  ]
}